{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm\n",
    "import sqlite3\n",
    "import seaborn as sns\n",
    "import patsy\n",
    "import statsmodels.formula.api as sm\n",
    "from sklearn.linear_model import LassoCV, LassoLarsCV, Lasso\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from lifelines import KaplanMeierFitter\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "import itertools\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "import rpy2.ipython\n",
    "%load_ext rpy2.ipython.rmagic\n",
    "\n",
    "from scripts.lib.stats import raise_low, lrt_phreg, phreg_aic, mannwhitneyu\n",
    "from scripts.lib.plotting import boxplot_with_points, load_style, residuals_plot\n",
    "from skbio.diversity.alpha import chao1, simpson_e\n",
    "from skbio.stats import subsample_counts\n",
    "from skbio import DistanceMatrix\n",
    "from skbio.stats.ordination import pcoa\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "concat = lambda list_of_lists: list(itertools.chain(*list_of_lists))\n",
    "richness = lambda x: (x > 0).sum()\n",
    "incidence = lambda x: (x > 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_style = load_style('paper')\n",
    "\n",
    "color_map = loaded_style['color_map']\n",
    "mark_map = loaded_style['mark_map']\n",
    "assign_significance_symbol = loaded_style['assign_significance_symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.lib.data import load_data\n",
    "loaded_data = load_data('res/C2013.results.db')\n",
    "gl = globals()\n",
    "gl.update(loaded_data)\n",
    "\n",
    "print(loaded_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with data in which we've dropped dens = nan results\n",
    "\n",
    "meta = (mouse[lambda x: x.cohort == 'C2013']\n",
    "            .join(conc)\n",
    "            .dropna(subset=['dens'])\n",
    "       ).sample(frac=1)  # Randomize sample order\n",
    "miceA = meta.index\n",
    "taxa_details = rabund.loc[meta.index].apply(lambda x: pd.Series({'mean_abund': np.mean(x),\n",
    "                                                                 'incidence': incidence(x)})).T\n",
    "cdata = count.loc[miceA]\n",
    "rdata = rabund.loc[miceA]\n",
    "adata = abund.loc[miceA]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeSeq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i meta -i cdata -o res_treatment -o res_sex -o res_interact\n",
    "\n",
    "library('DESeq2')\n",
    "\n",
    "meta$site = factor(meta$site)\n",
    "meta$treatment = factor(meta$treatment)\n",
    "meta$treatment = relevel(meta$treatment, 'control')\n",
    "\n",
    "dd <- DESeqDataSetFromMatrix(countData=t(cdata),\n",
    "                     colData=meta,\n",
    "                     design=~treatment * sex + site)\n",
    "ddr <- DESeq(dd, test=\"Wald\", fitType=\"parametric\", quiet=TRUE)\n",
    "print(resultsNames(ddr))\n",
    "res_treatment <- as(results(ddr, cooksCutoff = FALSE, contrast=c('treatment', 'acarbose', 'control')), 'data.frame')\n",
    "res_sex <- as(results(ddr, cooksCutoff = FALSE, contrast=c('sex', 'male', 'female')), 'data.frame')\n",
    "res_interact <- as(results(ddr, cooksCutoff = FALSE), 'data.frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in [res_treatment, res_sex, res_interact]:\n",
    "    res.set_index(taxa_details.index, inplace=True)\n",
    "\n",
    "\n",
    "taxa_details['treatment_effect'] = res_treatment.log2FoldChange\n",
    "taxa_details['treatment_p'] = res_treatment.pvalue\n",
    "taxa_details['sex_effect'] = res_sex.log2FoldChange\n",
    "taxa_details['sex_p'] = res_sex.pvalue\n",
    "taxa_details['interact_effect'] = res_interact.log2FoldChange\n",
    "taxa_details['interact_p'] = res_interact.pvalue\n",
    "\n",
    "result = taxa_details.loc[taxa_details[lambda x: (x.mean_abund > 0.0001)\n",
    "                                                & (x.incidence > 0.05)].index]\n",
    "result['treatment_padj'] = fdrcorrection(result.treatment_p)[1]\n",
    "result['sex_padj'] = fdrcorrection(result.sex_p)[1]\n",
    "result['interact_padj'] = fdrcorrection(result.interact_p)[1]\n",
    "result = result.join(taxonomy)\n",
    "result.genus = result.genus.apply(lambda x: '' if x is None else x)\n",
    "\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"OTUs affect by treatment\")\n",
    "d = rabund.loc[:,result[lambda x: x.treatment_padj < 0.05].index]\n",
    "print(d.shape[1])\n",
    "print(d.sum(axis=1).median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"OTUs affect by sex\")\n",
    "d = rabund.loc[:,result[lambda x: x.sex_padj < 0.05].index]\n",
    "print(d.shape[1])\n",
    "print(d.sum(axis=1).median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"OTUs affect by sex-by-treatment interaction\")\n",
    "d = rabund.loc[:,result[lambda x: x.interact_padj < 0.05].index]\n",
    "print(d.shape[1])\n",
    "print(d.sum(axis=1).median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot('sex', 'Otu0004', hue='treatment', data=rdata.join(meta)[meta.site=='UT'], split=True, jitter=True)\n",
    "plt.yscale('symlog', linthreshy=0.01)\n",
    "\n",
    "result.loc[['Otu0001', 'Otu0004']].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any particularly influential outliers?\n",
    "\n",
    "_data = meta.join(abund).dropna(subset=['butyrate'])\n",
    "_data['is_outlier'] = False\n",
    "#_data['is_outlier'].loc['JLc0836'] = True\n",
    "\n",
    "sns.pairplot(_data,\n",
    "             vars=['acetate', 'butyrate', 'lactate', 'propionate', 'Otu0001'],\n",
    "             hue='is_outlier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = (meta\n",
    "             .join(adata)       # Use estimated absolute abundance instead of just relative.\n",
    "             .dropna(subset=['Otu0001', 'butyrate'])\n",
    "#             .drop('JLc0836')   # Drop the weirdo outlier\n",
    "             .sample(frac=1.0)  # Shuffle order for CV purposes\n",
    "        )\n",
    "\n",
    "feat = 'propionate'\n",
    "\n",
    "fit = sm.ols('np.log(raise_low({})) ~ treatment * sex * site'.format(feat), data=_data).fit()\n",
    "resid = fit.resid\n",
    "\n",
    "top_taxa = taxa_details[lambda x: (x.mean_abund > 0.0001)\n",
    "                                  & (x.incidence > 0.05)].index\n",
    "\n",
    "lasso_cv = LassoCV(cv=10)\n",
    "lasso_cv.fit(_data.loc[resid.index, top_taxa], resid)\n",
    "print(lasso_cv.alpha_)\n",
    "\n",
    "lasso = Lasso(alpha=lasso_cv.alpha_)\n",
    "pred = cross_val_predict(lasso, _data.loc[resid.index, top_taxa], resid, cv=10)\n",
    "plt.scatter(pred, resid)\n",
    "print(sp.stats.spearmanr(pred, resid))\n",
    "\n",
    "result[feat] = pd.Series(lasso_cv.coef_, index=top_taxa, name=feat)\n",
    "\n",
    "(taxonomy.join(pd.Series(lasso_cv.coef_, index=top_taxa, name='coef'))\n",
    "         .dropna(subset=['coef'])\n",
    "         .sort_values('coef', ascending=False)\n",
    "         [lambda x: x.coef != 0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = (meta\n",
    "             .join(adata)       # Use estimated absolute abundance instead of just relative.\n",
    "             .dropna(subset=['Otu0001', 'butyrate'])\n",
    "#             .drop('JLc0836')   # Drop the weirdo outlier\n",
    "             .sample(frac=1.0)  # Shuffle order for CV purposes\n",
    "        )\n",
    "\n",
    "feat = 'lactate'\n",
    "\n",
    "fit = sm.ols('np.log(raise_low({})) ~ treatment * sex * site'.format(feat), data=_data).fit()\n",
    "resid = fit.resid\n",
    "\n",
    "top_taxa = taxa_details[lambda x: (x.mean_abund > 0.0001)\n",
    "                                  & (x.incidence > 0.05)].index\n",
    "\n",
    "lasso_cv = LassoCV(cv=10)\n",
    "lasso_cv.fit(_data.loc[resid.index, top_taxa], resid)\n",
    "print(lasso_cv.alpha_)\n",
    "\n",
    "lasso = Lasso(alpha=lasso_cv.alpha_)\n",
    "pred = cross_val_predict(lasso, _data.loc[resid.index, top_taxa], resid, cv=10)\n",
    "plt.scatter(pred, resid)\n",
    "print(sp.stats.spearmanr(pred, resid))\n",
    "\n",
    "result[feat] = pd.Series(lasso_cv.coef_, index=top_taxa, name=feat)\n",
    "\n",
    "(taxonomy.join(pd.Series(lasso_cv.coef_, index=top_taxa, name='coef'))\n",
    "         .dropna(subset=['coef'])\n",
    "         .sort_values('coef', ascending=False)\n",
    "         [lambda x: x.coef != 0]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = (meta\n",
    "             .join(adata)       # Use estimated absolute abundance instead of just relative.\n",
    "             .dropna(subset=['Otu0001', 'butyrate'])\n",
    "#             .drop('JLc0836')   # Drop the weirdo outlier\n",
    "             .sample(frac=1.0)  # Shuffle order for CV purposes\n",
    "        )\n",
    "\n",
    "feat = 'butyrate'\n",
    "\n",
    "fit = sm.ols('np.log(raise_low({})) ~ treatment * sex * site'.format(feat), data=_data).fit()\n",
    "resid = fit.resid\n",
    "\n",
    "top_taxa = taxa_details[lambda x: (x.mean_abund > 0.0001)\n",
    "                                  & (x.incidence > 0.05)].index\n",
    "\n",
    "lasso_cv = LassoCV(cv=10)\n",
    "lasso_cv.fit(_data.loc[resid.index, top_taxa], resid)\n",
    "print(lasso_cv.alpha_)\n",
    "\n",
    "lasso = Lasso(alpha=lasso_cv.alpha_)\n",
    "pred = cross_val_predict(lasso, _data.loc[resid.index, top_taxa], resid, cv=10)\n",
    "plt.scatter(pred, resid)\n",
    "print(sp.stats.spearmanr(pred, resid))\n",
    "\n",
    "result[feat] = pd.Series(lasso_cv.coef_, index=top_taxa, name=feat)\n",
    "\n",
    "(taxonomy.join(pd.Series(lasso_cv.coef_, index=top_taxa, name='coef'))\n",
    "         .dropna(subset=['coef'])\n",
    "         .sort_values('coef', ascending=False)\n",
    "         [lambda x: x.coef != 0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = (meta\n",
    "             .join(adata)       # Use estimated absolute abundance instead of just relative.\n",
    "             .dropna(subset=['Otu0001', 'butyrate'])\n",
    "#             .drop('JLc0836')   # Drop the weirdo outlier\n",
    "             .sample(frac=1.0)  # Shuffle order for CV purposes\n",
    "        )\n",
    "\n",
    "feat = 'acetate'\n",
    "\n",
    "fit = sm.ols('np.log(raise_low({})) ~ treatment * sex * site'.format(feat), data=_data).fit()\n",
    "resid = fit.resid\n",
    "\n",
    "top_taxa = taxa_details[lambda x: (x.mean_abund > 0.0001)\n",
    "                                  & (x.incidence > 0.05)].index\n",
    "\n",
    "lasso_cv = LassoCV(cv=10)\n",
    "lasso_cv.fit(_data.loc[resid.index, top_taxa], resid)\n",
    "print(lasso_cv.alpha_)\n",
    "\n",
    "lasso = Lasso(alpha=lasso_cv.alpha_)\n",
    "pred = cross_val_predict(lasso, _data.loc[resid.index, top_taxa], resid, cv=10)\n",
    "plt.scatter(pred, resid)\n",
    "print(sp.stats.spearmanr(pred, resid))\n",
    "\n",
    "result[feat] = pd.Series(lasso_cv.coef_, index=top_taxa, name=feat)\n",
    "\n",
    "(taxonomy.join(pd.Series(lasso_cv.coef_, index=top_taxa, name='coef'))\n",
    "         .dropna(subset=['coef'])\n",
    "         .sort_values('coef', ascending=False)\n",
    "         [lambda x: x.coef != 0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "output_columns = ['incidence', 'mean_abund',\n",
    "        'treatment_effect', 'treatment_padj',\n",
    "        'sex_effect', 'sex_padj',\n",
    "        'interact_effect', 'interact_padj',\n",
    "        'phylum', 'class', 'order', 'family', 'genus']\n",
    "#result[output_columns].sort_values('interact_padj')\n",
    "#result['treatment_sign'] = np.sign(result.treatment_effect)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "result[lambda x: (x.treatment_sign == +1) & (x.treatment_padj < 0.05)].incidence.count()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(rdata[result[lambda x: x.treatment_padj < 0.05].index].sum(axis=1).median())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a = result.groupby(['phylum', 'class', 'order', 'family']).incidence.count()\n",
    "b = result[lambda x: x.treatment_padj < 0.05].groupby(['phylum', 'class', 'order', 'family']).incidence.count()\n",
    "\n",
    "tax_summary = pd.DataFrame({'out_of': a, 'hits': b})\n",
    "\n",
    "tax_summary.hits.fillna(0, inplace=True)\n",
    "tax_summary['frac'] = tax_summary.hits / tax_summary.out_of\n",
    "tax_summary"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "result['treatment_sign'] = np.sign(result.treatment_effect)\n",
    "a = result.groupby(['phylum', 'class', 'order', 'family']).incidence.count()\n",
    "b = result[lambda x: (x.treatment_padj < 0.05) & (x.treatment_sign == -1)].groupby(['phylum', 'class', 'order', 'family']).incidence.count()\n",
    "c = result[lambda x: (x.treatment_padj < 0.05) & (x.treatment_sign == +1)].groupby(['phylum', 'class', 'order', 'family']).incidence.count()\n",
    "\n",
    "tax_summary = pd.DataFrame({'out_of': a, 'decreased': b, 'increased': c})\n",
    "\n",
    "tax_summary.decreased.fillna(0, inplace=True)\n",
    "tax_summary.increased.fillna(0, inplace=True)\n",
    "tax_summary['frac_decreased'] = tax_summary.decreased / tax_summary.out_of\n",
    "tax_summary['frac_increased'] = tax_summary.increased / tax_summary.out_of\n",
    "\n",
    "tax_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['log_mean_abund'] = np.log10(result.mean_abund)\n",
    "\n",
    "output_columns = ['incidence', 'mean_abund', 'log_mean_abund',\n",
    "        'treatment_effect', 'treatment_padj',\n",
    "        'sex_effect', 'sex_padj',\n",
    "        'interact_effect', 'interact_padj',\n",
    "        'propionate', 'butyrate', 'acetate', 'lactate',\n",
    "        'phylum', 'class', 'order', 'family', 'genus']\n",
    "\n",
    "\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('build/otu_details.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "result[output_columns].to_excel(writer, sheet_name='Sheet1')\n",
    "\n",
    "# Get the xlsxwriter workbook and worksheet objects.\n",
    "workbook  = writer.book\n",
    "worksheet = writer.sheets['Sheet1']\n",
    "\n",
    "# Add comments to column headers\n",
    "worksheet.write_comment('B1', 'Fraction of all samples with at least one read assigned to the OTU')\n",
    "worksheet.write_comment('C1', 'Mean relative abundance')\n",
    "worksheet.write_comment('D1', 'Log-base-10 of mean relative abundance')\n",
    "worksheet.write_comment('E1', 'Coefficient on treatment term in DESeq2 analysis')\n",
    "worksheet.write_comment('G1', 'Coefficient on sex term in DESeq2 analysis')\n",
    "worksheet.write_comment('I1', 'Coefficient on sex-by-treatment term in DESeq2 analysis')\n",
    "worksheet.write_comment('K1', 'Coefficient on OTU term in propionate LASSO analysis')\n",
    "worksheet.write_comment('L1', 'Coefficient on OTU term in butyrate LASSO analysis')\n",
    "worksheet.write_comment('M1', 'Coefficient on OTU term in acetate LASSO analysis')\n",
    "worksheet.write_comment('N1', 'Coefficient on OTU term in lactate LASSO analysis')\n",
    "\n",
    "# Format incidence column\n",
    "worksheet.set_column('B:B', None, workbook.add_format({'num_format': '0%'}))\n",
    "worksheet.conditional_format('B1:B999', {'type': 'data_bar', 'min_value': 0, 'max_value': 1,\n",
    "                                         'bar_color': '#555555'})\n",
    "\n",
    "# Format mean abundance column\n",
    "worksheet.set_column('C:C', None, workbook.add_format({'num_format': '0.0E+0'}))\n",
    "\n",
    "# Format transformed mean abundance column\n",
    "worksheet.set_column('D:D', None, workbook.add_format({'num_format': '0.0'}))\n",
    "worksheet.conditional_format('D1:D999', {'type': '2_color_scale',\n",
    "                                         'min_color': '#ffffff', 'max_color': '#ffe46d'})\n",
    "\n",
    "# Format DeSeq2 coefficient columns\n",
    "deseq_effect_fmt = workbook.add_format({'num_format': '0.0'})\n",
    "worksheet.set_column('E:E', None, deseq_effect_fmt)\n",
    "worksheet.set_column('G:G', None, deseq_effect_fmt)\n",
    "worksheet.set_column('I:I', None, deseq_effect_fmt)\n",
    "\n",
    "# Format LASSO coefficient columns\n",
    "lasso_effect_fmt = workbook.add_format({'num_format': '0.000000'})\n",
    "worksheet.set_column('K:N', None, lasso_effect_fmt)\n",
    "\n",
    "# Format DeSeq2 p-values\n",
    "pvalue_fmt = {'type': 'icon_set',\n",
    "     'icon_style': '3_traffic_lights',\n",
    "     'icons': [{'criteria': '<', 'type': 'number', 'value': 0.05},\n",
    "               {'criteria': '<', 'type': 'number', 'value': 0.001}]}\n",
    "worksheet.conditional_format('F1:F999', pvalue_fmt)\n",
    "worksheet.conditional_format('H1:H999', pvalue_fmt)\n",
    "worksheet.conditional_format('J1:J999', pvalue_fmt)\n",
    "# Narrow the cell width\n",
    "worksheet.set_column('F:F', 2)\n",
    "worksheet.set_column('H:H', 2)\n",
    "worksheet.set_column('J:J', 2)\n",
    "\n",
    "\n",
    "\n",
    "# Format effect sizes\n",
    "effect_fmt = {'type': '3_color_scale',\n",
    "                      'min_color': '#7787d6',\n",
    "                      'min_type': 'percentile',\n",
    "                      'min_value': 0,\n",
    "                      'mid_color': '#ffffff',\n",
    "                      'mid_type': 'percentile',\n",
    "                      'mid_value': 50,\n",
    "                      'max_color': '#ffe46d',\n",
    "                      'max_type': 'percentile',\n",
    "                      'max_value': 100,\n",
    "                      }\n",
    "worksheet.conditional_format('E1:E999', effect_fmt)\n",
    "worksheet.conditional_format('G1:G999', effect_fmt)\n",
    "worksheet.conditional_format('I1:I999', effect_fmt)\n",
    "#worksheet.conditional_format('K1:K999', effect_fmt)\n",
    "worksheet.conditional_format('L1:L999', effect_fmt)\n",
    "worksheet.conditional_format('M1:M999', effect_fmt)\n",
    "worksheet.conditional_format('N1:N999', effect_fmt)\n",
    "\n",
    "# Special formatting for propionate (since minimum is 0)\n",
    "assert result['propionate'].min() >= 0\n",
    "worksheet.conditional_format('K1:K999',\n",
    "                     {'type': '2_color_scale',\n",
    "                      'min_color': '#ffffff',\n",
    "                      'min_type': 'percentile',\n",
    "                      'min_value': 0,\n",
    "                      'max_color': '#ffe46d',\n",
    "                      'max_type': 'percentile',\n",
    "                      'max_value': 100,\n",
    "                      })\n",
    "\n",
    "worksheet.autofilter(0, 0, *result[output_columns].shape)\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}