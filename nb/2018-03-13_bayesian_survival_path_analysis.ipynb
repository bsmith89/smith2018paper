{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm\n",
    "import sqlite3\n",
    "import seaborn as sns\n",
    "import patsy\n",
    "from sklearn.decomposition import PCA\n",
    "from lifelines import KaplanMeierFitter\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "# import rpy2.ipython\n",
    "# %load_ext rpy2.ipython.rmagic\n",
    "\n",
    "from scripts.lib.stats import raise_low, lrt_phreg, phreg_aic\n",
    "from scripts.lib.plotting import boxplot_with_points, load_style\n",
    "\n",
    "from contextlib import contextmanager\n",
    "\n",
    "def model_to_eval_input(model, drop=None, include=None):\n",
    "    all_vars = [v.name for v in model.vars]\n",
    "    if include is None:\n",
    "        if drop is None:\n",
    "            include = all_vars\n",
    "        else:\n",
    "            include = set(all_vars) - set(drop)\n",
    "    else:\n",
    "        if drop is not None:\n",
    "            include = set(include) - set(drop)\n",
    "    out = {getattr(model, key): model.test_point[key]\n",
    "            for key in model.test_point\n",
    "            if key in include}\n",
    "    return out\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def temp_assign(update_dict):\n",
    "    saved_dict = {}\n",
    "    for var in update_dict:\n",
    "        saved_dict[var] = var.get_value()\n",
    "        var.set_value(update_dict[var])\n",
    "    yield\n",
    "    for var in update_dict:\n",
    "        var.set_value(saved_dict[var])\n",
    "        \n",
    "def sample_ppc(model, trace, update_shared_dict={}, samples=1, **kwargs):\n",
    "    with model:\n",
    "        with temp_assign(update_shared_dict):\n",
    "            sim = pm.sample_ppc(trace, samples=samples, **kwargs)\n",
    "            return sim\n",
    "        \n",
    "def age_at_first(events, interval_bounds=None):\n",
    "    events = np.asanyarray(events)\n",
    "    if interval_bounds is None:\n",
    "        interval_bounds = np.arange(len(events))\n",
    "    return interval_bounds[np.argmax(events > 0, axis=-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_style = load_style('paper')\n",
    "\n",
    "color_map = loaded_style['color_map']\n",
    "mark_map = loaded_style['mark_map']\n",
    "assign_significance_symbol = loaded_style['assign_significance_symbol']\n",
    "figure_ft = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.lib.data import load_data\n",
    "loaded_data = load_data('res/C2013.results.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse = loaded_data['mouse']\n",
    "conc = loaded_data['conc']\n",
    "abund = loaded_data['abund']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "\n",
    "def exposure_m(exit, intervals, entry=None):\n",
    "    \"\"\"Build per-subject exposure matrix.\n",
    "    \n",
    "    This matrix has entries in cells corresonding to\n",
    "    the amount of time spent in each time interval.\n",
    "    \n",
    "    \"\"\"\n",
    "    if entry is None:\n",
    "        entry = np.zeros_like(exit)\n",
    "        \n",
    "    assert entry.min() >= intervals[0]\n",
    "    assert exit.max() <= intervals[-1]\n",
    "    assert np.all(entry < exit)\n",
    "    interval_size = intervals[1:] - intervals[:-1]\n",
    "    assert np.all(interval_size > 0)\n",
    "    \n",
    "    \n",
    "    after_entry = np.less.outer(entry, intervals[1:])\n",
    "    before_exit = np.greater.outer(exit, intervals[:-1])\n",
    "    \n",
    "    idx_first_in = (~after_entry).sum(axis=1)\n",
    "    idx_last_in = before_exit.sum(axis=1) - 1\n",
    "    time_present_first = intervals[idx_first_in + 1] - entry\n",
    "    time_present_last = exit - intervals[idx_last_in]\n",
    "    \n",
    "    exposed = (after_entry & before_exit).astype(float) * interval_size\n",
    "    exposed[np.arange(len(entry)), idx_first_in] = time_present_first\n",
    "    exposed[np.arange(len(entry)), idx_last_in] = time_present_last\n",
    "    \n",
    "    return exposed\n",
    "\n",
    "def test_exposure_m():\n",
    "    entry = np.array([0.9, 1.0, 1.1, 0.9, 1.0, 1.1, 0.9, 1.0, 1.1])\n",
    "    exit = np.array([1.9, 1.9, 1.9, 2, 2, 2, 2.1, 2.1, 2.1])\n",
    "    intervals = np.arange(0, 4)\n",
    "    out = exposure_m(exit, intervals, entry=entry)\n",
    "    assert np.allclose(out,\n",
    "                       np.array([[ 0.1,  0.9,  0. ],\n",
    "                                 [ 0. ,  0.9,  0. ],\n",
    "                                 [ 0. ,  0.9,  0. ],\n",
    "                                 [ 0.1,  1. ,  0. ],\n",
    "                                 [ 0. ,  1. ,  0. ],\n",
    "                                 [ 0. ,  1. ,  0. ],\n",
    "                                 [ 0.1,  1. ,  0.1],\n",
    "                                 [ 0. ,  1. ,  0.1],\n",
    "                                 [ 0. ,  0.9,  0.1]])\n",
    "                      ), out\n",
    "\n",
    "    \n",
    "def event_m(exit, intervals, censored=None):\n",
    "    \"\"\"Build per-subject event matrix.\n",
    "    \n",
    "    This matrix has entries in cells corresponding to the\n",
    "    time intervals during which a subject died.\n",
    "    \n",
    "    Events which occur at the interval break are included\n",
    "    in the following interval.\n",
    "    \n",
    "    \"\"\"\n",
    "    interval_size = intervals[1:] - intervals[:-1]\n",
    "    assert np.all(interval_size > 0)\n",
    "    assert exit.min() >= intervals[0]\n",
    "    assert exit.max() <= intervals[-1]\n",
    "    after_exit_interval = np.less_equal.outer(exit, intervals[:-1])\n",
    "    before_exit_interval = np.greater.outer(exit, intervals[1:])\n",
    "#    print(after_exit_interval)\n",
    "#    print(before_exit_interval)\n",
    "    event = (~after_exit_interval & ~before_exit_interval).astype(int)\n",
    "    if censored is not None:\n",
    "        event[np.argwhere(censored),:] = 0\n",
    "#    print(event)\n",
    "    return event\n",
    "\n",
    "def test_event_m():\n",
    "    exit = np.array([1.9, 2, 2.1])\n",
    "    intervals = np.arange(0, 4)\n",
    "    out = event_m(exit, intervals)\n",
    "    assert np.all(out == np.array([[0, 1, 0],\n",
    "                                   [0, 1, 0],\n",
    "                                   [0, 0, 1]]))\n",
    "    \n",
    "test_event_m()\n",
    "test_exposure_m()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_adj = conc.copy()\n",
    "conc_adj.butyrate = raise_low(conc_adj.butyrate)\n",
    "\n",
    "data = (mouse[mouse.cohort.isin(['C2013'])]\n",
    "             .join(conc_adj).join(abund)\n",
    "             .dropna(subset=['age_at_death_or_censor', 'age_at_collect',\n",
    "                             'propionate', 'Otu0001'])\n",
    "        )\n",
    "data['censored'] = ~data.dead.astype(bool)\n",
    "\n",
    "njects = len(data)\n",
    "\n",
    "# Discretization\n",
    "interval_length = 10\n",
    "interval_bounds = np.arange(data.age_at_collect.min(),\n",
    "                            data.age_at_death_or_censor.max() + interval_length + 1,\n",
    "                            interval_length)\n",
    "m_intervals = len(interval_bounds) - 1\n",
    "\n",
    "# Design\n",
    "x_di = patsy.dmatrix('treatment * site * sex', data=data).design_info\n",
    "u = len(x_di.column_names) - 1\n",
    "x_design = lambda d: (patsy.build_design_matrices([x_di], d, return_type='dataframe')[0]\n",
    "                           .drop('Intercept', axis='columns'))\n",
    "\n",
    "# SCFAs\n",
    "y_di = patsy.dmatrix('propionate + butyrate + acetate', data=data).design_info\n",
    "v = len(y_di.column_names) - 1\n",
    "y_design = lambda d: (patsy.build_design_matrices([y_di], d,return_type='dataframe')[0]\n",
    "                           .drop('Intercept', axis='columns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as modelA:\n",
    "    x = theano.shared(x_design(data).values)\n",
    "    y = theano.shared(y_design(data).values)\n",
    "    exposure = theano.shared(exposure_m(exit=data.age_at_death_or_censor,\n",
    "                                        intervals=interval_bounds,\n",
    "                                        entry=data.age_at_collect))\n",
    "    event = theano.shared(event_m(exit=data.age_at_death_or_censor,\n",
    "                                  intervals=interval_bounds,\n",
    "                                  censored=data.censored))\n",
    "    \n",
    "    # SCFA model\n",
    "    alpha = pm.Normal('alpha', sd=10, shape=(u, v))\n",
    "    alpha_0 = pm.Normal('alpha_0', sd=10, shape=v)\n",
    "    # TODO: Rename expect_y to expect_y_log\n",
    "    expect_y = pm.Deterministic('expect_y', tt.dot(x, alpha) + alpha_0)\n",
    "    chol_packed = pm.LKJCholeskyCov('chol_packed', n=v, eta=2, sd_dist=pm.HalfCauchy.dist(beta=2.5, shape=v))\n",
    "    chol = pm.Deterministic('chol', pm.expand_packed_triangular(3, chol_packed))\n",
    "    obs_y = pm.MvNormal('obs_y', mu=expect_y, chol=chol, observed=tt.log(y))\n",
    "\n",
    "    lambda0 = pm.Gamma('lambda0', 0.01, 0.01, shape=m_intervals, testval=np.repeat(0.01, m_intervals))\n",
    "    beta_x = pm.Normal('beta_x', sd=10, shape=(u, 1))\n",
    "    beta_y = pm.Normal('beta_y', sd=10, shape=(v, 1))\n",
    "    expect_ph = pm.Deterministic('expect_ph', tt.exp(tt.dot(x, beta_x) + tt.dot(y, beta_y)))\n",
    "    expect_hazard = pm.Deterministic('expect_hazard', exposure * tt.outer(expect_ph, lambda0))\n",
    "    obs_event = pm.Poisson('obs_event', mu=expect_hazard, observed=event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with modelA:\n",
    "    traceA = pm.sample(1000, chains=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(enumerate(x_di.column_names[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation of counterfactuals\n",
    "\n",
    "# I use a PPC to sample predictions for\n",
    "# control and acarbose treated, male mice, at UM\n",
    "# collected on the same day as the youngest in my real data (779 days).\n",
    "# First I simulate SCFA concentrations and then I use these\n",
    "# concentrations as input to a second simulation where I simulate\n",
    "# death events.\n",
    "\n",
    "_d = pd.DataFrame({'treatment': ['acarbose', 'control'] * 4,\n",
    "                   'site': ['UM'] * 4 + ['UT'] * 4,\n",
    "                   'sex': (['female'] * 2 + ['male'] * 2) * 2})\n",
    "\n",
    "_x = x_design(_d)\n",
    "\n",
    "#_x = np.array([[0, 0, 0, 0, 0, 0, 0],\n",
    "#               [1, 0, 0, 0, 0, 0, 0],\n",
    "#               [0, 0, 1, 0, 0, 0, 0],\n",
    "#               [1, 0, 1, 0, 1, 0, 0],\n",
    "#               [0, 1, 0, 0, 0, 0, 0],\n",
    "#               [1, 1, 0, 1, 0, 0, 0],\n",
    "#               [0, 1, 1, 0, 0, 1, 0],\n",
    "#               [1, 1, 1, 1, 1, 1, 1]], dtype=float)\n",
    "_y = np.array([[0, 0, 0],\n",
    "               [0, 0, 0],\n",
    "               [0, 0, 0],\n",
    "               [0, 0, 0],\n",
    "               [0, 0, 0],\n",
    "               [0, 0, 0],\n",
    "               [0, 0, 0],\n",
    "               [0, 0, 0]], dtype=float)\n",
    "_exposure = np.ones((8, 56), dtype=float)\n",
    "_exposure.fill(10)\n",
    "\n",
    "scfa_sim = np.empty((len(traceA), 8, 3))\n",
    "event_sim = np.empty((len(traceA), 8, _exposure.shape[-1]))\n",
    "for i, samp in enumerate(traceA):\n",
    "    # Acarbose treated mouse\n",
    "    simA1 = sample_ppc(modelA, [samp], {x: _x, y: _y, exposure: _exposure},\n",
    "                       vars=[modelA.obs_y], progressbar=False)\n",
    "    scfa_sim[i] = simA1['obs_y']\n",
    "    simA2 = sample_ppc(modelA, [samp], {x: _x, y: scfa_sim[i], exposure: _exposure},\n",
    "                       vars=[modelA.obs_event], progressbar=False)\n",
    "    event_sim[i] = simA2['obs_event'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in ['low', 'mid', 'high']:\n",
    "    _d[col_name] = np.nan\n",
    "\n",
    "_d[['low', 'mid', 'high']] = np.percentile(age_at_first(event_sim, interval_bounds), [5, 50, 95], axis=0).T\n",
    "\n",
    "with temp_assign({x: _x}):\n",
    "    scfa_expect = (tt.exp(modelA.expect_y)\n",
    "            .eval({modelA.alpha_0: traceA.alpha_0.mean(0),\n",
    "                   modelA.alpha: traceA.alpha.mean(0)}))\n",
    "with temp_assign({x: _x, y: scfa_expect}):\n",
    "    ph_scfa = modelA.expect_ph.eval({modelA.beta_x: np.zeros((7,1)),\n",
    "                                     modelA.beta_y: traceA.beta_y.mean(0)})\n",
    "    ph_design = modelA.expect_ph.eval({modelA.beta_x: traceA.beta_x.mean(0),\n",
    "                                       modelA.beta_y: np.zeros((3,1))})\n",
    "    \n",
    "for i, col_name in enumerate(['propionate', 'butyrate', 'acetate']):\n",
    "    _d[col_name] = scfa_expect[:,i]\n",
    "_d['ph_scfa'] = np.log(ph_scfa)\n",
    "_d['ph_design'] = np.log(ph_design)\n",
    "\n",
    "_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.posteriorplot.plot_posterior(traceA, varnames=['beta_y'])\n",
    "plt.savefig('/Users/bjsmith/Desktop/path_analysis_posterior_y.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for treat, (low, mid, high) in zip(y_di.column_names[1:], np.percentile(traceA.beta_y[:,:,0], [2.5, 50, 97.5], 0).T):\n",
    "    print(f'{treat:<10}\\t{low:+0.3f}\\t{mid:+0.3f}\\t{high:+0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for treat, (low, mid, high) in zip(x_di.column_names[1:], np.percentile(traceA.beta_x[:,:,0], [2.5, 50, 97.5], 0).T):\n",
    "    print(f'{treat:<45} {low:+0.3}\\t{mid:+0.3}\\t{high:+0.03}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, molecule_id in enumerate(y_di.column_names[1:]):\n",
    "    print(f'**{molecule_id}**')\n",
    "    for treat, (low, mid, high) in zip(x_di.column_names[1:], np.percentile(traceA.alpha[:,:,i], [2.5, 50, 97.5], 0).T):\n",
    "        print(f'{treat:<45} {low:+0.3}\\t{mid:+0.3}\\t{high:+0.03}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(traceA, varnames=['alpha', 'alpha_0', 'beta_y', 'beta_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(enumerate(y_di.column_names[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(enumerate(x_di.column_names[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(traceA, varnames=['alpha', 'beta_x', 'beta_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_a, _b = traceA.beta_y[:,0,0], traceA.beta_x[:,0,0]\n",
    "plt.scatter(_a, _b, s=4)\n",
    "sp.stats.pearsonr(_a, _b)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}