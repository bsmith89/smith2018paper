{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm\n",
    "import sqlite3\n",
    "import seaborn as sns\n",
    "import patsy\n",
    "from sklearn.decomposition import PCA\n",
    "from lifelines import KaplanMeierFitter\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "import itertools\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "import rpy2.ipython\n",
    "%load_ext rpy2.ipython.rmagic\n",
    "\n",
    "from scripts.lib.stats import raise_low, lrt_phreg, phreg_aic, mannwhitneyu\n",
    "from scripts.lib.plotting import boxplot_with_points, load_style, residuals_plot\n",
    "from skbio.diversity.alpha import chao1, simpson_e\n",
    "from skbio.stats import subsample_counts\n",
    "from skbio import DistanceMatrix\n",
    "from skbio.stats.ordination import pcoa\n",
    "\n",
    "concat = lambda list_of_lists: list(itertools.chain(*list_of_lists))\n",
    "richness = lambda x: (x > 0).sum()\n",
    "\n",
    "def order_within(df, groupby, sortby, ascending=True):\n",
    "    return (df.sort_values(sortby, ascending=ascending)\n",
    "              .groupby(groupby)\n",
    "              .apply(lambda x: pd.Series(range(len(x)),\n",
    "                                         index=x.index,\n",
    "                                         name='order'))\n",
    "              .reset_index(level=0)\n",
    "              ['order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_style = load_style('paper')\n",
    "\n",
    "color_map = loaded_style['color_map']\n",
    "mark_map = loaded_style['mark_map']\n",
    "assign_significance_symbol = loaded_style['assign_significance_symbol']\n",
    "savefig = loaded_style['savefig']\n",
    "fullwidth = loaded_style['fullwidth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.lib.data import load_data\n",
    "loaded_data = load_data('res/C2013.results.db')\n",
    "\n",
    "con = loaded_data['con']\n",
    "conc = loaded_data['conc']\n",
    "mols = loaded_data['mols']\n",
    "mol_c_count = loaded_data['mol_c_count']\n",
    "mouse = loaded_data['mouse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = (pd.read_sql(\"\"\"\n",
    "    SELECT mouse_id, rrs_library_id, taxon_id, tally\n",
    "    FROM rrs_library_taxon_count\n",
    "    JOIN rrs_library_metadata USING (rrs_library_id)\n",
    "    WHERE taxon_level = 'unique'\n",
    "    AND spike_id NOT NULL\n",
    "                    \"\"\", con=con,\n",
    "                    index_col=['mouse_id', 'rrs_library_id', 'taxon_id'])\n",
    "        # Reshape into wide-format\n",
    "        ['tally'].unstack().fillna(0).astype(int)\n",
    "        # Drop libraries without an associated mouse_id\n",
    "        .reset_index().dropna(subset=['mouse_id']).set_index('mouse_id')\n",
    "        .drop('rrs_library_id', axis='columns')\n",
    "        )\n",
    "assert count.index.is_unique\n",
    "rabund = count.apply(lambda x: x / x.sum(), axis='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy = (pd.read_sql(\n",
    "    \"\"\"\n",
    "    SELECT taxon_id AS seq_id, taxon_id_b AS otu\n",
    "    FROM taxonomy\n",
    "    WHERE taxon_level = 'unique'\n",
    "      AND taxon_level_b = 'otu-0.03'\n",
    "      AND confidence > 0.7\n",
    "    \"\"\",\n",
    "    con=con, index_col=['seq_id']))\n",
    "taxonomy['mean_abund'] = rabund.mean(axis='index')\n",
    "taxonomy.dropna(subset=['mean_abund'], inplace=True)\n",
    "taxonomy['order'] = order_within(taxonomy, 'otu', 'mean_abund', ascending=False)\n",
    "taxonomy['short_seq_id'] = taxonomy.otu + '_' + (taxonomy.order + 1).astype(str).str.pad(width=4, fillchar='0')\n",
    "\n",
    "rabund_rn = rabund.rename(columns=taxonomy.short_seq_id)\n",
    "taxonomy = taxonomy.reset_index().set_index('short_seq_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Commons Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy[taxonomy.otu.isin(['Otu0001', 'Otu0004'])].sort_values(['mean_abund'], ascending=False).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy.sort_values('mean_abund', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phylotype Analysis (Partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subseq_counts = pd.read_sql(\"\"\"\n",
    "    SELECT taxon_id, taxon_id_b, SUM(tally) AS total\n",
    "    FROM rrs_library_taxon_count\n",
    "    JOIN taxonomy USING (taxon_id, taxon_level)\n",
    "    WHERE taxon_level = 'unique'\n",
    "      AND taxon_id_b IN ('Otu0001', 'Otu0004')\n",
    "    GROUP BY taxon_id\n",
    "    ORDER BY total DESC\n",
    "    \"\"\", con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subseq_counts[subseq_counts.total > 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subseq_counts.total.quantile([0, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.95, 0.99, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Probability of seeing a particular erroneous sequence:')\n",
    "# ASSUMPTIONS:\n",
    "error_rate = 0.001       # Constant error probability\n",
    "subs_alphabet_size = 3  # Given an erroneous base, exactly equal probability of any other base being substituted\n",
    "seq_length =  240\n",
    "\n",
    "specific_error_rate = np.exp(np.log(1 - error_rate) * (seq_length - 1) +\n",
    "                             np.log(error_rate / subs_alphabet_size) * 1)\n",
    "print(specific_error_rate)\n",
    "\n",
    "print()\n",
    "print('Probability of a perfect sequence:')\n",
    "perfect_seq_rate = (1 - error_rate) ** seq_length\n",
    "print(perfect_seq_rate)\n",
    "\n",
    "print()\n",
    "print('Ratio of specific error seq to perfect seqs:')\n",
    "print(specific_error_rate / perfect_seq_rate)\n",
    "\n",
    "print()\n",
    "print(\"^For every correct sequence we expect this many with a particular (single-position) error^\")\n",
    "\n",
    "print()\n",
    "max_count = subseq_counts.total.max()\n",
    "specific_errors_expect = max_count * specific_error_rate / perfect_seq_rate\n",
    "print(('So, in our library, where we recovered {} of the most common sequence,'\n",
    "       ' we expect all ({} * {}) 1-base deviations from that sequence to have {:.1f} copies')\n",
    "          .format(max_count, seq_length,\n",
    "                  subs_alphabet_size,\n",
    "                  specific_errors_expect)\n",
    "     )\n",
    "\n",
    "print()\n",
    "print(('If the distribution were Poisson, and therefore nearly normal'\n",
    "       ' it would have a mean of {0:.1f} and a stdev of sqrt({0:.1f})={1:.1f}').format(specific_errors_expect,\n",
    "                                                                  np.sqrt(specific_errors_expect)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Supplemental Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mouse.join(rabund_rn, how='inner')\n",
    "data['total_otu1'] = data[list(taxonomy[taxonomy.otu.isin(['Otu0001'])].index)].sum(axis='columns')\n",
    "data = data.sort_values([ 'site'\n",
    "                        , 'treatment'\n",
    "                        , 'total_otu1'\n",
    "                        ], ascending=[ True\n",
    "                                     , False\n",
    "                                     , True\n",
    "                                     ])\n",
    "\n",
    "# otus = ['Otu0001', 'Otu0004', 'Otu0005']\n",
    "# cmaps = [mpl.cm.PuOr, mpl.cm.PiYG, mpl.cm.coolwarm]\n",
    "otus = ['Otu0001', 'Otu0004']\n",
    "rename_otus = {'Otu0001_0001': 'OTU-1.1',\n",
    "               'Otu0001_0002': 'OTU-1.2',\n",
    "               'Otu0001_0003': 'OTU-1.3',\n",
    "               'Otu0001_0004': 'OTU-1.4',\n",
    "               'Otu0004_0001': 'OTU-4.1',\n",
    "               'Otu0004_0002': 'OTU-4.2',\n",
    "               'Otu0004_0003': 'OTU-4.3',\n",
    "               'Otu0004_0004': 'OTU-4.4',\n",
    "               'Otu0001_other': 'Other OTU-1',\n",
    "               'Otu0004_other': 'Other OTU-4'\n",
    "\n",
    "              }\n",
    "\n",
    "cmaps = [mpl.cm.PuOr, mpl.cm.PiYG]\n",
    "\n",
    "fig, axs = plt.subplots(nrows=len(otus), figsize=(fullwidth, 1.75 * len(otus)), sharex=True, sharey=True)\n",
    "take_top_k_seqs = 4\n",
    "\n",
    "legends = []\n",
    "for otu, ax, cm in zip(otus, axs, cmaps):\n",
    "    color = np.row_stack([cm(np.linspace(0, 1, take_top_k_seqs)),\n",
    "                         np.array([0.4, 0.4, 0.4, 1])])\n",
    "    all_seqs = list(taxonomy[taxonomy.otu.isin([otu])].sort_values('mean_abund', ascending=False).index)\n",
    "    top_seqs = all_seqs[:take_top_k_seqs]\n",
    "    other_seqs = all_seqs[take_top_k_seqs:]\n",
    "    data[top_seqs] = rabund_rn[top_seqs]\n",
    "    data['{}_other'.format(otu)] = rabund_rn[other_seqs].sum(axis='columns')\n",
    "    data['{}_total'.format(otu)] = rabund_rn[all_seqs].sum(axis='columns')\n",
    "\n",
    "\n",
    "    cols = top_seqs + ['{}_other'.format(otu)]\n",
    "    #data[cols] = data[cols].apply(lambda x: x / x.sum(), axis='columns')\n",
    "    (data[cols].rename(columns=rename_otus)\n",
    "         .plot.bar(stacked=True, width=1,\n",
    "                   ax=ax, color=color))\n",
    "    ax.set_xticklabels([])\n",
    "    legends.append(ax.legend(bbox_to_anchor=(1.01, 1)))\n",
    "    \n",
    "    split_location = 0\n",
    "    for site in ['TJL', 'UM', 'UT']:\n",
    "        d0 = data[data.site == site]\n",
    "        for treatment in ['control', 'acarbose']:\n",
    "            d1 = d0[d0.treatment == treatment]\n",
    "            ax.annotate('{} {}'.format(site, treatment),\n",
    "                        xy=(split_location / len(data) + 0.01, 0.91),\n",
    "                        xycoords='axes fraction', rotation=0,\n",
    "                        fontsize=5)\n",
    "            split_location += len(d1)\n",
    "            ax.axvline(split_location - 0.5, color='k', linestyle='--')\n",
    "        ax.axvline(split_location - 0.5, color='k')     \n",
    "        \n",
    "annotations = []\n",
    "for panel, ax in zip(['A', 'B'], axs):\n",
    "    letter = ax.annotate(panel, xy=(0, 1.03), xycoords='axes fraction', fontweight='heavy')\n",
    "    annotations.append(letter)\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_yticklabels('{:2.0f}%'.format(x * 100) for x in ax.get_yticks()[:-1])\n",
    "    \n",
    "ax.set_xlabel('Mouse')\n",
    "\n",
    "savefig(fig, 'fig/s247_phylotypes',\n",
    "        bbox_inches='tight', bbox_extra_artists=legends + annotations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "180px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}